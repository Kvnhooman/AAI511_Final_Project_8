{"cells":[{"cell_type":"code","execution_count":null,"id":"2c6b643c","metadata":{"tags":["parameters"],"id":"2c6b643c"},"outputs":[],"source":["from pathlib import Path\n","BASE_DIR = Path(BASE_DIR)  # ensures you can do BASE_DIR / 'file.pkl'"]},{"cell_type":"code","execution_count":null,"id":"a58d1c77","metadata":{"id":"a58d1c77"},"outputs":[],"source":["MODEL_NAME = 'hybrid'"]},{"cell_type":"code","execution_count":null,"id":"cec0cc6c","metadata":{"id":"cec0cc6c"},"outputs":[],"source":["import pickle\n","import numpy as np\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.utils.data import Dataset, DataLoader\n","from pathlib import Path\n","from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n","import zipfile\n","from pathlib import Path"]},{"cell_type":"code","execution_count":null,"id":"tZf2sm59bqg8","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":326},"id":"tZf2sm59bqg8","outputId":"df789a35-1a49-4868-935c-97a6832d8172","executionInfo":{"status":"error","timestamp":1754905769067,"user_tz":420,"elapsed":44,"user":{"displayName":"Devin Eror","userId":"08010257872820414663"}}},"outputs":[{"output_type":"error","ename":"FileNotFoundError","evalue":"[Errno 2] No such file or directory: '/content/cnn_data.pkl.zip'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipython-input-268616791.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mextract_to\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/content/processed_data'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mzipfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mZipFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mzip_ref\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m   \u001b[0mzip_ref\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextractall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mextract_to\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.11/zipfile.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, file, mode, compression, allowZip64, compresslevel, strict_timestamps, metadata_encoding)\u001b[0m\n\u001b[1;32m   1293\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1294\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1295\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilemode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1296\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1297\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mfilemode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodeDict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/cnn_data.pkl.zip'"]}],"source":["zip_path = '/content/cnn_data.pkl.zip'\n","extract_to = '/content/processed_data'\n","\n","with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n","  zip_ref.extractall(extract_to)\n","\n","print(\"Unzipped to:\", extract_to)"]},{"cell_type":"code","execution_count":null,"id":"80d1a67b","metadata":{"id":"80d1a67b"},"outputs":[],"source":["\n","BASE_DIR = Path('/content')\n","\n","# Sequence length  (match your LSTM window size)\n","WINDOW_LEN = 50\n","\n","# Pitch range for piano-roll\n","PITCH_START = 21\n","PITCH_END   = 108\n","NUM_PITCHES = PITCH_END - PITCH_START + 1  # 88"]},{"cell_type":"markdown","id":"4703da00","metadata":{"id":"4703da00"},"source":["### Define Piano-Roll Conversion"]},{"cell_type":"code","execution_count":null,"id":"34151767","metadata":{"id":"34151767"},"outputs":[],"source":["def seq_to_pianoroll(seq,\n","                     pitch_start=PITCH_START,\n","                     num_pitches=NUM_PITCHES):\n","    \"\"\"\n","    seq: np.array of shape (WINDOW_LEN, 3), where seq[:,0] = pitch.\n","    Returns a binary piano-roll: shape (1, num_pitches, WINDOW_LEN).\n","    \"\"\"\n","    pr = np.zeros((num_pitches, seq.shape[0]), dtype=np.float32)\n","    for t, note in enumerate(seq):\n","        p = int(note[0])\n","        pr[p - pitch_start, t] = 1.0\n","    return pr[np.newaxis, :, :]"]},{"cell_type":"markdown","id":"edd77559","metadata":{"id":"edd77559"},"source":["### Load LSTM Windows & Build CNN Features"]},{"cell_type":"code","execution_count":null,"id":"Ho4njSNGmNej","metadata":{"id":"Ho4njSNGmNej"},"outputs":[],"source":["import pickle, numpy as np\n","from collections import Counter\n","\n","with open(BASE_DIR/'lstm_data.pkl','rb') as f:\n","    data = pickle.load(f)\n","\n","# Handle either tuple/list or dict-shaped pickles\n","if isinstance(data, dict):\n","    # try common key names; adjust if your dict uses different ones\n","    X_lstm = data.get('X') or data.get('X_lstm') or data.get('X_windows')\n","    y      = data.get('y') or data.get('labels')\n","    le     = data.get('le') or data.get('label_encoder')\n","else:\n","    X_lstm, y, le = data  # as in your code\n","\n","# Basic sanity prints\n","print(\"Type(X_lstm):\", type(X_lstm))\n","try:\n","    print(\"len(X_lstm):\", len(X_lstm))\n","except TypeError:\n","    print(\"X_lstm has no len(); shape:\", getattr(X_lstm, 'shape', 'N/A'))\n","\n","print(\"Type(y):\", type(y), \"len(y):\", len(y) if hasattr(y, '__len__') else 'N/A')\n","if hasattr(le, 'classes_'):\n","    print(\"Label classes in encoder:\", le.classes_)\n","\n","# Peek at labels\n","try:\n","    print(\"Label sample:\", list(y)[:5])\n","except Exception as e:\n","    print(\"Could not preview labels:\", e)\n","\n","# Check class distribution (works if y is list/array of strings/ints)\n","try:\n","    print(\"Class counts:\", Counter(list(y)))\n","except Exception as e:\n","    print(\"Could not count classes:\", e)\n","\n","assert hasattr(X_lstm, '__len__') and len(X_lstm) == len(y), \"X and y must be same length\"\n","assert len(X_lstm) > 0, \"X_lstm is empty â€” upstream data build likely failed.\"\n"]},{"cell_type":"code","execution_count":null,"id":"cc3ed5a3","metadata":{"id":"cc3ed5a3"},"outputs":[],"source":["# --- Unified Data Loading & Conversion (tuple/dict-safe) ---\n","from pathlib import Path\n","import pickle, numpy as np\n","\n","def _pick_first(d, keys):\n","    for k in keys:\n","        if k in d and d[k] is not None:\n","            return d[k]\n","    return None\n","\n","def load_splits(base: Path):\n","    # Optional label encoder\n","    le = None\n","    le_path = base / 'label_encoder.pkl'\n","    if le_path.exists():\n","        with open(le_path, 'rb') as f:\n","            le = pickle.load(f)\n","\n","    # Train split can be tuple OR dict depending on your preprocessing run\n","    with open(base / 'lstm_data.pkl', 'rb') as f:\n","        data = pickle.load(f)\n","\n","    if isinstance(data, dict):\n","        X_train_l = _pick_first(data, ['X','X_lstm','X_windows'])\n","        y_train   = _pick_first(data, ['y','labels'])\n","        le_in     = _pick_first(data, ['le','label_encoder'])\n","        if le is None: le = le_in\n","    else:\n","        # Expect (X_train_l, y_train, le) or (X_train_l, y_train)\n","        if len(data) == 3:\n","            X_train_l, y_train, le_in = data\n","            if le is None: le = le_in\n","        elif len(data) == 2:\n","            X_train_l, y_train = data\n","        else:\n","            raise ValueError(f\"Unexpected lstm_data.pkl format: len={len(data)}\")\n","\n","    # Dev/Test are expected as tuples\n","    with open(base / 'lstm_dev.pkl', 'rb') as f:\n","        X_dev_l, y_dev = pickle.load(f)\n","    with open(base / 'lstm_test.pkl', 'rb') as f:\n","        X_test_l, y_test = pickle.load(f)\n","\n","    if hasattr(le, \"classes_\"):\n","        print(\"Label classes:\", le.classes_)\n","    else:\n","        print(\"[warn] Label encoder missing or has no classes_\")\n","\n","    return X_train_l, y_train, X_dev_l, y_dev, X_test_l, y_test, le\n","\n","def to_pianoroll_batch(seqs):\n","    # assumes seq_to_pianoroll(seq) is defined earlier in the notebook\n","    return np.stack([seq_to_pianoroll(s) for s in seqs], axis=0)\n","\n","# BASE_DIR must be set (or injected by the orchestrator) to your processed_data folder\n","X_train_l, y_train, X_dev_l, y_dev, X_test_l, y_test, le = load_splits(BASE_DIR)\n","\n","X_train_c = to_pianoroll_batch(X_train_l)\n","X_dev_c   = to_pianoroll_batch(X_dev_l)\n","X_test_c  = to_pianoroll_batch(X_test_l)\n","\n","print(\"LSTM shapes:\", getattr(X_train_l, 'shape', len(X_train_l)), getattr(X_dev_l, 'shape', len(X_dev_l)), getattr(X_test_l, 'shape', len(X_test_l)))\n","print(\"CNN shapes: \", X_train_c.shape, X_dev_c.shape, X_test_c.shape)\n","print(\"Labels train/dev/test:\", len(y_train), len(y_dev), len(y_test))\n"]},{"cell_type":"code","execution_count":null,"id":"827c8353","metadata":{"id":"827c8353"},"outputs":[],"source":["\n","np.save(BASE_DIR/'cnn_train_data.npy',  X_train_c)\n","np.save(BASE_DIR/'cnn_train_labels.npy', y_train)\n","np.save(BASE_DIR/'cnn_dev_data.npy',    X_dev_c)\n","np.save(BASE_DIR/'cnn_dev_labels.npy',   y_dev)\n","np.save(BASE_DIR/'cnn_test_data.npy',   X_test_c)\n","np.save(BASE_DIR/'cnn_test_labels.npy',  y_test)\n","print(\"âœ… CNN feature files written.\")"]},{"cell_type":"markdown","id":"fd977e73","metadata":{"id":"fd977e73"},"source":["### Create dataloaders"]},{"cell_type":"code","execution_count":null,"id":"ad22b059","metadata":{"id":"ad22b059"},"outputs":[],"source":["# Hybrid Dataset & DataLoaders\n","import torch\n","from torch.utils.data import Dataset, DataLoader\n","\n","class HybridDataset(Dataset):\n","    def __init__(self, lstm_data, cnn_data, labels):\n","        self.lstm = torch.tensor(lstm_data, dtype=torch.float32)\n","        self.cnn  = torch.tensor(cnn_data,  dtype=torch.float32)\n","        self.labels = torch.tensor(labels, dtype=torch.long)\n","\n","    def __len__(self):\n","        return len(self.labels)\n","\n","    def __getitem__(self, idx):\n","        return self.lstm[idx], self.cnn[idx], self.labels[idx]\n","\n","# Build datasets\n","train_ds = HybridDataset(X_train_l, X_train_c, y_train)\n","dev_ds   = HybridDataset(X_dev_l,   X_dev_c,   y_dev)\n","test_ds  = HybridDataset(X_test_l,  X_test_c,  y_test)\n","\n","# Create loaders\n","batch_size = 32\n","train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n","dev_loader   = DataLoader(dev_ds,   batch_size=batch_size)\n","test_loader  = DataLoader(test_ds,  batch_size=batch_size)\n","\n","\n","lstm_b, cnn_b, y_b = next(iter(train_loader))\n","print(\"LSTM batch shape:\", lstm_b.shape)\n","print(\"CNN batch shape: \", cnn_b.shape)\n","print(\"Label batch shape:\", y_b.shape)"]},{"cell_type":"markdown","id":"1f2c562b","metadata":{"id":"1f2c562b"},"source":["### Defining a Hybrid Model"]},{"cell_type":"code","execution_count":null,"id":"68a0f604","metadata":{"id":"68a0f604"},"outputs":[],"source":["# Device selection\n","device = torch.device('mps' if torch.backends.mps.is_available()\n","                      else 'cuda' if torch.cuda.is_available()\n","                      else 'cpu')\n","print(\"Using device:\", device)\n","\n","class HybridNet(nn.Module):\n","    def __init__(self, num_classes):\n","        super().__init__()\n","        # CNN branch\n","        self.cnn_branch = nn.Sequential(\n","            nn.Conv2d(1, 16, kernel_size=3, padding=1),\n","            nn.ReLU(),\n","            nn.MaxPool2d((2,2)),\n","            nn.Conv2d(16,32, kernel_size=3, padding=1),\n","            nn.ReLU(),\n","            nn.AdaptiveAvgPool2d((1,1))\n","        )\n","        # LSTM branch\n","        self.lstm_branch = nn.LSTM(\n","            input_size=3,\n","            hidden_size=64,\n","            num_layers=1,\n","            batch_first=True\n","        )\n","        # classifier\n","        self.fc = nn.Linear(32 + 64, num_classes)\n","\n","    def forward(self, x_lstm, x_cnn):\n","        # LSTM path\n","        out_l, _ = self.lstm_branch(x_lstm)\n","        feat_l   = out_l[:, -1, :]\n","        # CNN path\n","        feat_c   = self.cnn_branch(x_cnn)\n","        feat_c   = feat_c.view(feat_c.size(0), -1)\n","        # Concatenate and classify\n","        combined = torch.cat([feat_l, feat_c], dim=1)\n","        return self.fc(combined)\n","\n","# Instantiate\n","num_classes = len(le.classes_)\n","model = HybridNet(num_classes).to(device)\n","print(model)"]},{"cell_type":"markdown","id":"cb1b98bb","metadata":{"id":"cb1b98bb"},"source":["### Training Setup"]},{"cell_type":"code","execution_count":null,"id":"8c603f5a","metadata":{"id":"8c603f5a"},"outputs":[],"source":["# Hyperparameters\n","batch_size    = 32\n","learning_rate = 1e-3\n","num_epochs    = 20\n","\n","# Loss and optimizer\n","criterion     = nn.CrossEntropyLoss()\n","optimizer     = optim.Adam(model.parameters(), lr=learning_rate)\n","\n","# Track best dev accuracy\n","best_dev_acc  = 0.0\n","\n","print(f\"Training for {num_epochs} epochs on device {device}\")"]},{"cell_type":"markdown","id":"d3b2db50","metadata":{"id":"d3b2db50"},"source":["### Hybrid Model Training Loop"]},{"cell_type":"code","execution_count":null,"id":"c550c40e","metadata":{"id":"c550c40e"},"outputs":[],"source":["for epoch in range(1, num_epochs + 1):\n","    # â€”â€”â€” Training â€”â€”â€”\n","    model.train()\n","    train_losses = []\n","    for x_lstm, x_cnn, yb in train_loader:\n","        x_lstm, x_cnn, yb = x_lstm.to(device), x_cnn.to(device), yb.to(device)\n","        optimizer.zero_grad()\n","        logits = model(x_lstm, x_cnn)\n","        loss   = criterion(logits, yb)\n","        loss.backward()\n","        optimizer.step()\n","        train_losses.append(loss.item())\n","\n","    avg_train_loss = np.mean(train_losses)\n","\n","    # â€”â€”â€” Validation â€”â€”â€”\n","    model.eval()\n","    val_preds, val_true, val_losses = [], [], []\n","    with torch.no_grad():\n","        for x_lstm, x_cnn, yb in dev_loader:\n","            x_lstm, x_cnn, yb = x_lstm.to(device), x_cnn.to(device), yb.to(device)\n","            logits = model(x_lstm, x_cnn)\n","            loss   = criterion(logits, yb)\n","            val_losses.append(loss.item())\n","            preds = logits.argmax(dim=1).cpu().numpy()\n","            val_preds.extend(preds)\n","            val_true.extend(yb.cpu().numpy())\n","\n","    avg_val_loss = np.mean(val_losses)\n","    val_acc      = accuracy_score(val_true, val_preds)\n","\n","    print(f\"Epoch {epoch:2d}/{num_epochs}  \"\n","          f\"Train Loss: {avg_train_loss:.4f}  \"\n","          f\"Val Loss: {avg_val_loss:.4f}  \"\n","          f\"Val Acc: {val_acc:.4f}\")\n","\n","    # Save best model\n","    if val_acc > best_dev_acc:\n","        best_dev_acc = val_acc\n","        torch.save(model.state_dict(), BASE_DIR / 'best_hybrid.pth')\n","        print(\"  ðŸ”– New best hybrid model saved\")"]},{"cell_type":"code","execution_count":null,"id":"948767be","metadata":{"id":"948767be"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"d10c0470","metadata":{"id":"d10c0470"},"outputs":[],"source":["\n","import json, os\n","from pathlib import Path\n","from sklearn.metrics import accuracy_score, precision_recall_fscore_support, confusion_matrix, classification_report\n","import matplotlib.pyplot as plt\n","import numpy as np\n","\n","def _safe_metrics_dump(model_name, y_true_names, y_pred_names, labels):\n","    acc = accuracy_score(y_true_names, y_pred_names)\n","    precision_macro, recall_macro, f1_macro, _ = precision_recall_fscore_support(y_true_names, y_pred_names, average='macro', zero_division=0)\n","    precision_weighted, recall_weighted, f1_weighted, _ = precision_recall_fscore_support(y_true_names, y_pred_names, average='weighted', zero_division=0)\n","    report = classification_report(y_true_names, y_pred_names, digits=4, output_dict=True)\n","    outdir = Path('/mnt/data/artifacts')\n","    outdir.mkdir(parents=True, exist_ok=True)\n","    with open(outdir / f'metrics_{model_name}.json', 'w') as f:\n","        json.dump({\n","            \"model\": model_name,\n","            \"accuracy\": acc,\n","            \"precision_macro\": precision_macro,\n","            \"recall_macro\": recall_macro,\n","            \"f1_macro\": f1_macro,\n","            \"precision_weighted\": precision_weighted,\n","            \"recall_weighted\": recall_weighted,\n","            \"f1_weighted\": f1_weighted,\n","            \"classification_report\": report,\n","            \"labels\": list(labels)\n","        }, f, indent=2)\n","    cm = confusion_matrix(y_true_names, y_pred_names, labels=labels)\n","    plt.figure()\n","    im = plt.imshow(cm)\n","    plt.colorbar(im)\n","    plt.xticks(range(len(labels)), labels, rotation=45, ha='right')\n","    plt.yticks(range(len(labels)), labels)\n","    for (i, j), val in np.ndenumerate(cm):\n","        plt.text(j, i, int(val), ha='center', va='center')\n","    plt.xlabel(\"Predicted\")\n","    plt.ylabel(\"Actual\")\n","    plt.title(f\"Confusion Matrix - {model_name}\")\n","    plt.tight_layout()\n","    plt.savefig(outdir / f'confusion_{model_name}.png', dpi=150)\n","    plt.close()\n","\n","try:\n","    _labels = le.classes_ if 'le' in globals() else sorted(set(y_true_names) | set(y_pred_names))\n","    _model_name = MODEL_NAME if 'MODEL_NAME' in globals() else 'model'\n","    _safe_metrics_dump(_model_name, y_true_names, y_pred_names, _labels)\n","    print(f\"[patch] Saved metrics and confusion matrix for {_model_name} to /mnt/data/artifacts\")\n","except Exception as e:\n","    print(\"[patch] Unable to compute metrics from this notebook:\", e)\n"]}],"metadata":{"colab":{"gpuType":"T4","machine_shape":"hm","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.4"}},"nbformat":4,"nbformat_minor":5}