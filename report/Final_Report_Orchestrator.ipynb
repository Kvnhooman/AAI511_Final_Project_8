{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "38b1474d",
      "metadata": {
        "id": "38b1474d"
      },
      "source": [
        "# 🎼 Composer Classification — Colab Orchestrator (One-Click)\n",
        "This notebook runs the whole pipeline in **one Colab runtime**. It will:\n",
        "\n",
        "1) Mount Google Drive (optional but recommended)\n",
        "\n",
        "2) Find your **patched notebooks** automatically (or unzip `final_report_kit.zip` if present)\n",
        "\n",
        "3) Ensure Kaggle auth\n",
        "\n",
        "4) Inject parameters into each notebook\n",
        "\n",
        "5) Patch preprocessing to extract into a **writable** folder\n",
        "\n",
        "6) Execute **Preprocessing → (Hybrid/LSTM) → Evaluation** via nbclient\n",
        "\n",
        "7) Summarize metrics & show confusion matrices\n",
        "\n",
        "\n",
        "> Tip: If you see a Kaggle 403, upload your `kaggle.json` (Kaggle API token) to Drive and rerun the auth cell.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "db64d886",
      "metadata": {
        "id": "db64d886"
      },
      "source": [
        "## 0) Install dependencies (first run only)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "475cf97b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "475cf97b",
        "outputId": "27cd5e78-fae0-4878-eb90-a05f9149c9ea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m23.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.6/54.6 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for pretty_midi (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "# If this is your first run in a fresh Colab session, run this cell.\n",
        "!pip -q install kagglehub nbclient pretty_midi mido scikit-learn matplotlib pandas\n",
        "try:\n",
        "    import torch, torchvision, torchaudio  # often preinstalled on Colab GPU runtimes\n",
        "except Exception:\n",
        "    !pip -q install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cpu\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "32127103",
      "metadata": {
        "id": "32127103"
      },
      "source": [
        "## 1) Mount Drive (optional) & auto-discover the `notebooks/` folder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "896e5f4e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "896e5f4e",
        "outputId": "ecd40dab-4c1e-4692-bcab-68f6b1bc61f7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "NOTEBOOKS_DIR: /content/drive/MyDrive/ComposerReport/report/notebooks\n",
            "ARTIFACTS: /content/drive/MyDrive/ComposerReport/report/artifacts\n",
            "OUTPUT_DIR: /content/drive/MyDrive/ComposerReport/report/processed_data\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "from pathlib import Path\n",
        "import os, zipfile\n",
        "\n",
        "# Mount (safe to re-run)\n",
        "try:\n",
        "    drive.mount('/content/drive')\n",
        "except Exception as e:\n",
        "    print(\"Drive mount note:\", e)\n",
        "\n",
        "# If a kit zip is present in /content, unzip it for convenience\n",
        "if Path('/content/final_report_kit.zip').exists() and not Path('/content/report/notebooks').exists():\n",
        "    with zipfile.ZipFile('/content/final_report_kit.zip', 'r') as z:\n",
        "        z.extractall('/content')\n",
        "\n",
        "# Auto-detect the notebooks directory\n",
        "REQUIRED = {\n",
        "    \"AAI511_Final_Data_Preprocessing_2_PATCHED_preproc.ipynb\",\n",
        "    \"CNN_Hybrid_PATCHED_hybrid_CLEAN.ipynb\",\n",
        "    \"CNN_LSTM_Evaluation_PATCHED_eval.ipynb\",\n",
        "    \"LSTM_Training_PATCHED_lstm.ipynb\",\n",
        "}\n",
        "\n",
        "def has_all(dirpath: Path) -> bool:\n",
        "    names = {p.name for p in dirpath.glob(\"*.ipynb\")}\n",
        "    return REQUIRED.issubset(names)\n",
        "\n",
        "CANDIDATES = [\n",
        "    Path('/content/report/notebooks'),\n",
        "    Path('/content/drive/MyDrive/ComposerReport/report/notebooks'),\n",
        "    Path('/content/drive/MyDrive').resolve(),\n",
        "    Path('/content').resolve(),\n",
        "]\n",
        "\n",
        "NOTEBOOKS_DIR = None\n",
        "for base in CANDIDATES:\n",
        "    if base.is_dir():\n",
        "        # quick check on exact folder\n",
        "        if has_all(base):\n",
        "            NOTEBOOKS_DIR = base\n",
        "            break\n",
        "        # search shallow\n",
        "        for root, dirs, files in os.walk(base):\n",
        "            p = Path(root)\n",
        "            if has_all(p):\n",
        "                NOTEBOOKS_DIR = p\n",
        "                break\n",
        "        if NOTEBOOKS_DIR:\n",
        "            break\n",
        "\n",
        "assert NOTEBOOKS_DIR is not None, \"Couldn't find the patched notebooks. Upload `final_report_kit.zip` and run again, or set NOTEBOOKS_DIR manually.\"\n",
        "\n",
        "# Make artifacts & processed_data in a writable, local place\n",
        "ROOT = NOTEBOOKS_DIR.parent if NOTEBOOKS_DIR.name == 'notebooks' else Path('/content')\n",
        "ARTIFACTS = (ROOT / 'artifacts'); ARTIFACTS.mkdir(parents=True, exist_ok=True)\n",
        "OUTPUT_DIR = (ROOT / 'processed_data'); OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "print(\"NOTEBOOKS_DIR:\", NOTEBOOKS_DIR)\n",
        "print(\"ARTIFACTS:\", ARTIFACTS)\n",
        "print(\"OUTPUT_DIR:\", OUTPUT_DIR)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "610ba3d6",
      "metadata": {
        "id": "610ba3d6"
      },
      "source": [
        "## 2) Configuration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "35ed58b3",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "35ed58b3",
        "outputId": "fed2809f-2126-437a-ff0a-0a8e7af1f9f8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'KAGGLE_DATASET': 'blanderbuss/midi-classic-music',\n",
              " 'ZIP_FILENAME': None,\n",
              " 'TARGET_COMPOSERS': ['bach', 'beethoven', 'chopin', 'mozart'],\n",
              " 'RUN_PREPROCESS': True,\n",
              " 'RUN_HYBRID_TRAINING': True,\n",
              " 'RUN_LSTM_TRAINING': True}"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "# Edit these to your needs. Defaults are safe.\n",
        "CONFIG = {\n",
        "    # Kaggle dataset slug — change this to your dataset\n",
        "    \"KAGGLE_DATASET\": \"blanderbuss/midi-classic-music\",  # <--- set your actual slug here\n",
        "    \"ZIP_FILENAME\": None,  # or \"something.zip\" if dataset has multiple zips\n",
        "    # Target composers\n",
        "    \"TARGET_COMPOSERS\": [\"bach\",\"beethoven\",\"chopin\",\"mozart\"],\n",
        "    # Steps to run\n",
        "    \"RUN_PREPROCESS\": True,\n",
        "    \"RUN_HYBRID_TRAINING\": True,\n",
        "    \"RUN_LSTM_TRAINING\": True,\n",
        "}\n",
        "\n",
        "CONFIG\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b8f31b1a",
      "metadata": {
        "id": "b8f31b1a"
      },
      "source": [
        "## 3) Kaggle authentication (required for KaggleHub)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "0d7d9c05",
      "metadata": {
        "id": "0d7d9c05"
      },
      "outputs": [],
      "source": [
        "# import os, shutil\n",
        "# from pathlib import Path\n",
        "\n",
        "# home = Path.home()/\".kaggle\"\n",
        "# home.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# installed = False\n",
        "# for s in [Path(\"./kaggle.json\"),\n",
        "#           Path(\"/content/drive/MyDrive/kaggle.json\"),\n",
        "#           Path(\"/content/drive/MyDrive/.kaggle/kaggle.json\")]:\n",
        "#     if s.exists():\n",
        "#         shutil.copy(s, home/\"kaggle.json\"); os.chmod(home/\"kaggle.json\", 0o600)\n",
        "#         print(\"✅ Installed kaggle.json from\", s)\n",
        "#         installed = True\n",
        "#         break\n",
        "\n",
        "# if not installed:\n",
        "#     print(\"⚠️ kaggle.json not found. Public datasets may still require auth. Upload kaggle.json to Drive and re-run this cell if you hit 403 errors.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c83358b2",
      "metadata": {
        "id": "c83358b2"
      },
      "source": [
        "## 4) Helpers: parameter injection, preprocessing patch, and execution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "bc1513c4",
      "metadata": {
        "id": "bc1513c4"
      },
      "outputs": [],
      "source": [
        "import nbformat, re, json, traceback, os\n",
        "from nbclient import NotebookClient\n",
        "from nbformat.v4 import new_code_cell\n",
        "from pathlib import Path\n",
        "\n",
        "def inject_parameters(nb_path: Path, params: dict):\n",
        "    nb = nbformat.read(nb_path.as_posix(), as_version=4)\n",
        "    # Make/replace a cell at top defining the parameters\n",
        "    code_lines = []\n",
        "    for k, v in params.items():\n",
        "        if isinstance(v, str):\n",
        "            code_lines.append(f'{k} = {json.dumps(v)}')\n",
        "        elif isinstance(v, (list, tuple)):\n",
        "            code_lines.append(f'{k} = {json.dumps(v)}')\n",
        "        else:\n",
        "            code_lines.append(f'{k} = {repr(v)}')\n",
        "    cell = new_code_cell(\"\\n\".join(code_lines))\n",
        "    # Insert at top (index 0)\n",
        "    nb.cells.insert(0, cell)\n",
        "    return nb\n",
        "\n",
        "def patch_preprocessing_extraction(nb):\n",
        "    # Find a cell that uses kagglehub + zipfile and patch the extraction path to OUTPUT_DIR/extracted_midis\n",
        "    patched = False\n",
        "    for c in nb.cells:\n",
        "        if c.cell_type != 'code':\n",
        "            continue\n",
        "        src = c.source\n",
        "        if \"kagglehub.dataset_download\" in src and \"zipfile.ZipFile\" in src:\n",
        "            # recursive zip search\n",
        "            src = re.sub(r\"zips\\s=\\s\\[.*?\\]\",\n",
        "                         \"zips = []\\nfor _root, _dirs, _files in os.walk(download_root):\\n    for _fn in _files:\\n        if _fn.lower().endswith('.zip'):\\n            zips.append(os.path.join(_root, _fn))\",\n",
        "                         src, flags=re.DOTALL)\n",
        "            # set extract_path to OUTPUT_DIR/extracted_midis\n",
        "            src = re.sub(r\"extract_path\\s*=.*\",\n",
        "                         \"extract_path = os.fspath((Path(OUTPUT_DIR) / 'extracted_midis').resolve())\",\n",
        "                         src)\n",
        "            if \"from pathlib import Path\" not in src:\n",
        "                src = \"from pathlib import Path\\n\" + src\n",
        "            # midi_root uses extraction\n",
        "            src = re.sub(r\"midi_root\\s*=.*\", \"midi_root = extract_path\", src)\n",
        "            c.source = src\n",
        "            patched = True\n",
        "            break\n",
        "    return nb, patched\n",
        "\n",
        "def execute_notebook(nb, name: str):\n",
        "    out_path = ARTIFACTS / f\"{name}_EXECUTED.ipynb\"\n",
        "    print(\"▶️ Executing:\", name)\n",
        "    client = NotebookClient(nb, timeout=None, kernel_name='python3')\n",
        "    try:\n",
        "        executed = client.execute()\n",
        "    except Exception as e:\n",
        "        print(\"❌ Error while executing\", name, \"->\", type(e).__name__, e)\n",
        "        traceback.print_exc()\n",
        "        # Still save the partial output for debugging\n",
        "        nbformat.write(client.nb, out_path.as_posix())\n",
        "        raise\n",
        "    nbformat.write(executed, out_path.as_posix())\n",
        "    print(\"✅ Wrote:\", out_path)\n",
        "    return out_path\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Helper: replace fragile Hybrid loader with a safe one ---\n",
        "import nbformat\n",
        "from nbformat.v4 import new_code_cell\n",
        "\n",
        "SAFE_HYBRID_LOADER = r\"\"\"\n",
        "from pathlib import Path\n",
        "import os, pickle, numpy as np\n",
        "from collections import Counter\n",
        "\n",
        "# ensure BASE_DIR is a Path\n",
        "if not isinstance(BASE_DIR, Path):\n",
        "    BASE_DIR = Path(BASE_DIR)\n",
        "\n",
        "with open(BASE_DIR / 'lstm_data.pkl','rb') as f:\n",
        "    data = pickle.load(f)\n",
        "\n",
        "def first_non_none(*vals):\n",
        "    for v in vals:\n",
        "        if v is not None:\n",
        "            return v\n",
        "    return None\n",
        "\n",
        "# Support tuple/list or dict-shaped pickles\n",
        "if isinstance(data, dict):\n",
        "    X_lstm = first_non_none(data.get('X'), data.get('X_lstm'), data.get('X_windows'))\n",
        "    y      = first_non_none(data.get('y'), data.get('labels'))\n",
        "    le     = first_non_none(data.get('le'), data.get('label_encoder'))\n",
        "else:\n",
        "    if len(data) == 3:\n",
        "        X_lstm, y, le = data\n",
        "    elif len(data) == 2:\n",
        "        X_lstm, y = data\n",
        "        le = None\n",
        "    else:\n",
        "        raise ValueError(f\"Unexpected lstm_data.pkl format: len={len(data)}\")\n",
        "\n",
        "print(\"Type(X_lstm):\", type(X_lstm))\n",
        "try: print(\"len(X_lstm):\", len(X_lstm))\n",
        "except TypeError: print(\"X_lstm shape:\", getattr(X_lstm, 'shape', 'N/A'))\n",
        "print(\"Type(y):\", type(y), \"len(y):\", len(y) if hasattr(y, '__len__') else 'N/A')\n",
        "if getattr(le, \"classes_\", None) is not None:\n",
        "    print(\"Label classes:\", le.classes_)\n",
        "\n",
        "assert hasattr(X_lstm, '__len__') and len(X_lstm) == len(y), \"X and y must be same length\"\n",
        "assert len(X_lstm) > 0, \"X_lstm is empty — upstream preprocessing likely failed.\"\n",
        "\"\"\"\n",
        "\n",
        "def patch_hybrid_loader(nb):\n",
        "    \"\"\"\n",
        "    Find the cell that loads lstm_data.pkl using 'or' chaining and replace it with the safe loader.\n",
        "    Returns (nb, replaced: bool).\n",
        "    \"\"\"\n",
        "    replaced = False\n",
        "    for i, c in enumerate(nb.cells):\n",
        "        if c.cell_type != \"code\":\n",
        "            continue\n",
        "        src = c.source\n",
        "        if (\"lstm_data.pkl\" in src) and (\"data.get('X')\" in src or \"Handle either tuple/list or dict\" in src):\n",
        "            nb.cells[i] = new_code_cell(SAFE_HYBRID_LOADER)\n",
        "            replaced = True\n",
        "            break\n",
        "    return nb, replaced\n"
      ],
      "metadata": {
        "id": "SYt-Zt0jpzat"
      },
      "id": "SYt-Zt0jpzat",
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "8b84e8aa",
      "metadata": {
        "id": "8b84e8aa"
      },
      "source": [
        "## 5) Run the pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "63bf11ff",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "63bf11ff",
        "outputId": "2c4cf8ce-71fe-4e27-c11d-3af72dc33032"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔧 Patched preprocessing to extract into OUTPUT_DIR/extracted_midis\n",
            "▶️ Executing: PREPROCESSING\n",
            "✅ Wrote: /content/drive/MyDrive/ComposerReport/report/artifacts/PREPROCESSING_EXECUTED.ipynb\n",
            "🔧 Replaced fragile Hybrid loader with safe loader\n",
            "▶️ Executing: TRAIN_HYBRID\n",
            "❌ Error while executing TRAIN_HYBRID -> CellExecutionError An error occurred while executing the following cell:\n",
            "------------------\n",
            "\n",
            "from pathlib import Path, PurePath\n",
            "BASE_DIR = Path('/content/drive/MyDrive/ComposerReport/report/processed_data')\n",
            "print(\"HYBRID BASE_DIR ->\", BASE_DIR)\n",
            "import os\n",
            "print(\"Files in BASE_DIR:\", sorted([f for f in os.listdir(BASE_DIR) if f.endswith(\".pkl\")]))\n",
            "assert (BASE_DIR/\"lstm_data.pkl\").exists(), \"lstm_data.pkl not found in \" + str(BASE_DIR)\n",
            "assert (BASE_DIR/\"lstm_dev.pkl\").exists(),  \"lstm_dev.pkl not found in \"  + str(BASE_DIR)\n",
            "assert (BASE_DIR/\"lstm_test.pkl\").exists(), \"lstm_test.pkl not found in \" + str(BASE_DIR)\n",
            "\n",
            "------------------\n",
            "\n",
            "----- stdout -----\n",
            "HYBRID BASE_DIR -> /content/drive/MyDrive/ComposerReport/report/processed_data\n",
            "Files in BASE_DIR: []\n",
            "------------------\n",
            "\n",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n",
            "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)\n",
            "\u001b[0;32m/tmp/ipython-input-3519094063.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n",
            "\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Files in BASE_DIR:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mf\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBASE_DIR\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\".pkl\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32massert\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mBASE_DIR\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34m\"lstm_data.pkl\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"lstm_data.pkl not found in \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBASE_DIR\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;32massert\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mBASE_DIR\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34m\"lstm_dev.pkl\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;34m\"lstm_dev.pkl not found in \"\u001b[0m  \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBASE_DIR\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m      8\u001b[0m \u001b[0;32massert\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mBASE_DIR\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34m\"lstm_test.pkl\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"lstm_test.pkl not found in \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBASE_DIR\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\n",
            "\u001b[0;31mAssertionError\u001b[0m: lstm_data.pkl not found in /content/drive/MyDrive/ComposerReport/report/processed_data\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/tmp/ipython-input-1334599085.py\", line 52, in execute_notebook\n",
            "    executed = client.execute()\n",
            "               ^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/jupyter_core/utils/__init__.py\", line 164, in wrapped\n",
            "    return _runner_map[name].run(inner)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/jupyter_core/utils/__init__.py\", line 127, in run\n",
            "    return fut.result(None)\n",
            "           ^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.11/concurrent/futures/_base.py\", line 456, in result\n",
            "    return self.__get_result()\n",
            "           ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.11/concurrent/futures/_base.py\", line 401, in __get_result\n",
            "    raise self._exception\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/nbclient/client.py\", line 709, in async_execute\n",
            "    await self.async_execute_cell(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/nbclient/client.py\", line 1062, in async_execute_cell\n",
            "    await self._check_raise_for_error(cell, cell_index, exec_reply)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/nbclient/client.py\", line 918, in _check_raise_for_error\n",
            "    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)\n",
            "nbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:\n",
            "------------------\n",
            "\n",
            "from pathlib import Path, PurePath\n",
            "BASE_DIR = Path('/content/drive/MyDrive/ComposerReport/report/processed_data')\n",
            "print(\"HYBRID BASE_DIR ->\", BASE_DIR)\n",
            "import os\n",
            "print(\"Files in BASE_DIR:\", sorted([f for f in os.listdir(BASE_DIR) if f.endswith(\".pkl\")]))\n",
            "assert (BASE_DIR/\"lstm_data.pkl\").exists(), \"lstm_data.pkl not found in \" + str(BASE_DIR)\n",
            "assert (BASE_DIR/\"lstm_dev.pkl\").exists(),  \"lstm_dev.pkl not found in \"  + str(BASE_DIR)\n",
            "assert (BASE_DIR/\"lstm_test.pkl\").exists(), \"lstm_test.pkl not found in \" + str(BASE_DIR)\n",
            "\n",
            "------------------\n",
            "\n",
            "----- stdout -----\n",
            "HYBRID BASE_DIR -> /content/drive/MyDrive/ComposerReport/report/processed_data\n",
            "Files in BASE_DIR: []\n",
            "------------------\n",
            "\n",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n",
            "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)\n",
            "\u001b[0;32m/tmp/ipython-input-3519094063.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n",
            "\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Files in BASE_DIR:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mf\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBASE_DIR\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\".pkl\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32massert\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mBASE_DIR\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34m\"lstm_data.pkl\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"lstm_data.pkl not found in \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBASE_DIR\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;32massert\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mBASE_DIR\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34m\"lstm_dev.pkl\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;34m\"lstm_dev.pkl not found in \"\u001b[0m  \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBASE_DIR\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m      8\u001b[0m \u001b[0;32massert\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mBASE_DIR\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34m\"lstm_test.pkl\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"lstm_test.pkl not found in \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBASE_DIR\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\n",
            "\u001b[0;31mAssertionError\u001b[0m: lstm_data.pkl not found in /content/drive/MyDrive/ComposerReport/report/processed_data\n",
            "\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "CellExecutionError",
          "evalue": "An error occurred while executing the following cell:\n------------------\n\nfrom pathlib import Path, PurePath\nBASE_DIR = Path('/content/drive/MyDrive/ComposerReport/report/processed_data')\nprint(\"HYBRID BASE_DIR ->\", BASE_DIR)\nimport os\nprint(\"Files in BASE_DIR:\", sorted([f for f in os.listdir(BASE_DIR) if f.endswith(\".pkl\")]))\nassert (BASE_DIR/\"lstm_data.pkl\").exists(), \"lstm_data.pkl not found in \" + str(BASE_DIR)\nassert (BASE_DIR/\"lstm_dev.pkl\").exists(),  \"lstm_dev.pkl not found in \"  + str(BASE_DIR)\nassert (BASE_DIR/\"lstm_test.pkl\").exists(), \"lstm_test.pkl not found in \" + str(BASE_DIR)\n\n------------------\n\n----- stdout -----\nHYBRID BASE_DIR -> /content/drive/MyDrive/ComposerReport/report/processed_data\nFiles in BASE_DIR: []\n------------------\n\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)\n\u001b[0;32m/tmp/ipython-input-3519094063.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Files in BASE_DIR:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mf\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBASE_DIR\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\".pkl\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32massert\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mBASE_DIR\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34m\"lstm_data.pkl\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"lstm_data.pkl not found in \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBASE_DIR\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;32massert\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mBASE_DIR\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34m\"lstm_dev.pkl\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;34m\"lstm_dev.pkl not found in \"\u001b[0m  \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBASE_DIR\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32massert\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mBASE_DIR\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34m\"lstm_test.pkl\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"lstm_test.pkl not found in \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBASE_DIR\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\n\u001b[0;31mAssertionError\u001b[0m: lstm_data.pkl not found in /content/drive/MyDrive/ComposerReport/report/processed_data\n",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mCellExecutionError\u001b[0m                        Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-137669827.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     38\u001b[0m \"\"\"))\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m     \u001b[0mexecute_notebook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnb_h\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"TRAIN_HYBRID\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;31m# 5.3 LSTM training (optional)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-1334599085.py\u001b[0m in \u001b[0;36mexecute_notebook\u001b[0;34m(nb, name)\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0mclient\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNotebookClient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'python3'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m         \u001b[0mexecuted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"❌ Error while executing\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"->\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/jupyter_core/utils/__init__.py\u001b[0m in \u001b[0;36mwrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    162\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_runner_map\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m             \u001b[0m_runner_map\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_TaskRunner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 164\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_runner_map\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minner\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    165\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m     \u001b[0mwrapped\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcoro\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/jupyter_core/utils/__init__.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, coro)\u001b[0m\n\u001b[1;32m    125\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__runner_thread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m         \u001b[0mfut\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0masyncio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_coroutine_threadsafe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcoro\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__io_loop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfut\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    454\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mCancelledError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    455\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mFINISHED\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 456\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    457\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    458\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/concurrent/futures/_base.py\u001b[0m in \u001b[0;36m__get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    399\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    400\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 401\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    402\u001b[0m             \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    403\u001b[0m                 \u001b[0;31m# Break a reference cycle with the exception in self._exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/nbclient/client.py\u001b[0m in \u001b[0;36masync_execute\u001b[0;34m(self, reset_kc, **kwargs)\u001b[0m\n\u001b[1;32m    707\u001b[0m                 \u001b[0;31m# Ignore `'execution_count' in content` as it's always 1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    708\u001b[0m                 \u001b[0;31m# when store_history is False\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 709\u001b[0;31m                 await self.async_execute_cell(\n\u001b[0m\u001b[1;32m    710\u001b[0m                     \u001b[0mcell\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexecution_count\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode_cells_executed\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    711\u001b[0m                 )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/nbclient/client.py\u001b[0m in \u001b[0;36masync_execute_cell\u001b[0;34m(self, cell, cell_index, execution_count, store_history)\u001b[0m\n\u001b[1;32m   1060\u001b[0m             \u001b[0mcell\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_outputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1061\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1062\u001b[0;31m         \u001b[0;32mawait\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_raise_for_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcell\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexec_reply\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1063\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1064\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnb\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"cells\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcell_index\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/nbclient/client.py\u001b[0m in \u001b[0;36m_check_raise_for_error\u001b[0;34m(self, cell, cell_index, exec_reply)\u001b[0m\n\u001b[1;32m    916\u001b[0m         )\n\u001b[1;32m    917\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcell_allows_errors\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 918\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mCellExecutionError\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_cell_and_msg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcell\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexec_reply_content\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    919\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    920\u001b[0m     async def async_execute_cell(\n",
            "\u001b[0;31mCellExecutionError\u001b[0m: An error occurred while executing the following cell:\n------------------\n\nfrom pathlib import Path, PurePath\nBASE_DIR = Path('/content/drive/MyDrive/ComposerReport/report/processed_data')\nprint(\"HYBRID BASE_DIR ->\", BASE_DIR)\nimport os\nprint(\"Files in BASE_DIR:\", sorted([f for f in os.listdir(BASE_DIR) if f.endswith(\".pkl\")]))\nassert (BASE_DIR/\"lstm_data.pkl\").exists(), \"lstm_data.pkl not found in \" + str(BASE_DIR)\nassert (BASE_DIR/\"lstm_dev.pkl\").exists(),  \"lstm_dev.pkl not found in \"  + str(BASE_DIR)\nassert (BASE_DIR/\"lstm_test.pkl\").exists(), \"lstm_test.pkl not found in \" + str(BASE_DIR)\n\n------------------\n\n----- stdout -----\nHYBRID BASE_DIR -> /content/drive/MyDrive/ComposerReport/report/processed_data\nFiles in BASE_DIR: []\n------------------\n\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)\n\u001b[0;32m/tmp/ipython-input-3519094063.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Files in BASE_DIR:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mf\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBASE_DIR\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\".pkl\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32massert\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mBASE_DIR\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34m\"lstm_data.pkl\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"lstm_data.pkl not found in \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBASE_DIR\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;32massert\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mBASE_DIR\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34m\"lstm_dev.pkl\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;34m\"lstm_dev.pkl not found in \"\u001b[0m  \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBASE_DIR\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32massert\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mBASE_DIR\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34m\"lstm_test.pkl\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"lstm_test.pkl not found in \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBASE_DIR\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\n\u001b[0;31mAssertionError\u001b[0m: lstm_data.pkl not found in /content/drive/MyDrive/ComposerReport/report/processed_data\n"
          ]
        }
      ],
      "source": [
        "from pathlib import Path\n",
        "\n",
        "# 5.1 Preprocess\n",
        "if CONFIG.get(\"RUN_PREPROCESS\", True):\n",
        "    preproc_params = {\n",
        "        \"KAGGLE_DATASET\": CONFIG[\"KAGGLE_DATASET\"],\n",
        "        \"ZIP_FILENAME\": CONFIG[\"ZIP_FILENAME\"],\n",
        "        \"OUTPUT_DIR\": str(OUTPUT_DIR),\n",
        "        \"TARGET_COMPOSERS\": CONFIG[\"TARGET_COMPOSERS\"],\n",
        "    }\n",
        "    nb_pre = inject_parameters(NOTEBOOKS_DIR/\"AAI511_Final_Data_Preprocessing_2_PATCHED_preproc.ipynb\", preproc_params)\n",
        "    nb_pre, did_patch = patch_preprocessing_extraction(nb_pre)\n",
        "    if did_patch:\n",
        "        print(\"🔧 Patched preprocessing to extract into OUTPUT_DIR/extracted_midis\")\n",
        "    execute_notebook(nb_pre, \"PREPROCESSING\")\n",
        "\n",
        "# 5.2 Hybrid training (optional)\n",
        "if CONFIG.get(\"RUN_HYBRID_TRAINING\", False):\n",
        "    train_params = {\"BASE_DIR\": str(OUTPUT_DIR)}   # <- use OUTPUT_DIR exactly\n",
        "    nb_h = inject_parameters(NOTEBOOKS_DIR/\"CNN_Hybrid_PATCHED_hybrid_CLEAN.ipynb\", train_params)\n",
        "    nb_h, did_replace = patch_hybrid_loader(nb_h)\n",
        "    if did_replace:\n",
        "        print(\"🔧 Replaced fragile Hybrid loader with safe loader\")\n",
        "    else:\n",
        "        print(\"ℹ️ Hybrid loader already safe (no replacement needed)\")\n",
        "\n",
        "    # ⬇️ Force and verify BASE_DIR inside the executed notebook\n",
        "    from nbformat.v4 import new_code_cell\n",
        "    nb_h.cells.insert(1, new_code_cell(f\"\"\"\n",
        "from pathlib import Path, PurePath\n",
        "BASE_DIR = Path({repr(str(OUTPUT_DIR))})\n",
        "print(\"HYBRID BASE_DIR ->\", BASE_DIR)\n",
        "import os\n",
        "print(\"Files in BASE_DIR:\", sorted([f for f in os.listdir(BASE_DIR) if f.endswith(\".pkl\")]))\n",
        "assert (BASE_DIR/\"lstm_data.pkl\").exists(), \"lstm_data.pkl not found in \" + str(BASE_DIR)\n",
        "assert (BASE_DIR/\"lstm_dev.pkl\").exists(),  \"lstm_dev.pkl not found in \"  + str(BASE_DIR)\n",
        "assert (BASE_DIR/\"lstm_test.pkl\").exists(), \"lstm_test.pkl not found in \" + str(BASE_DIR)\n",
        "\"\"\"))\n",
        "\n",
        "    execute_notebook(nb_h, \"TRAIN_HYBRID\")\n",
        "\n",
        "# 5.3 LSTM training (optional)\n",
        "if CONFIG.get(\"RUN_LSTM_TRAINING\", False):\n",
        "    train_params = {\"BASE_DIR\": Path(OUTPUT_DIR).as_posix()}\n",
        "    nb_l = inject_parameters(NOTEBOOKS_DIR/\"LSTM_Training_PATCHED_lstm.ipynb\", train_params)\n",
        "    execute_notebook(nb_l, \"TRAIN_LSTM\")\n",
        "\n",
        "# 5.4 Evaluation (always run if present)\n",
        "eval_params = {\"BASE_DIR\": Path(OUTPUT_DIR).as_posix()}\n",
        "nb_e = inject_parameters(NOTEBOOKS_DIR/\"CNN_LSTM_Evaluation_PATCHED_eval.ipynb\", eval_params)\n",
        "execute_notebook(nb_e, \"EVALUATION\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b83b3feb",
      "metadata": {
        "id": "b83b3feb"
      },
      "source": [
        "## 6) Results summary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "53061b32",
      "metadata": {
        "id": "53061b32"
      },
      "outputs": [],
      "source": [
        "import json, pandas as pd\n",
        "from pathlib import Path\n",
        "from IPython.display import display\n",
        "\n",
        "metric_files = list(Path(ARTIFACTS).glob(\"metrics_*.json\"))\n",
        "rows = []\n",
        "for mf in metric_files:\n",
        "    with open(mf, 'r') as f:\n",
        "        d = json.load(f)\n",
        "    rows.append({\n",
        "        \"model\": d.get(\"model\"),\n",
        "        \"accuracy\": d.get(\"accuracy\"),\n",
        "        \"f1_macro\": d.get(\"f1_macro\"),\n",
        "        \"f1_weighted\": d.get(\"f1_weighted\"),\n",
        "        \"precision_macro\": d.get(\"precision_macro\"),\n",
        "        \"recall_macro\": d.get(\"recall_macro\"),\n",
        "    })\n",
        "\n",
        "if rows:\n",
        "    df = pd.DataFrame(rows).sort_values(by=\"accuracy\", ascending=False)\n",
        "    display(df)\n",
        "    out_csv = Path(ARTIFACTS) / \"model_comparison.csv\"\n",
        "    df.to_csv(out_csv, index=False)\n",
        "    print(\"Saved CSV ->\", out_csv)\n",
        "else:\n",
        "    print(\"No metrics_* JSON files in:\", ARTIFACTS)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cfff7143",
      "metadata": {
        "id": "cfff7143"
      },
      "source": [
        "## 7) Confusion matrices"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b50815ea",
      "metadata": {
        "id": "b50815ea"
      },
      "outputs": [],
      "source": [
        "from IPython.display import Image, display\n",
        "from pathlib import Path\n",
        "\n",
        "pngs = list(Path(ARTIFACTS).glob(\"confusion_*.png\"))\n",
        "if not pngs:\n",
        "    print(\"No confusion_*.png in:\", ARTIFACTS)\n",
        "for p in pngs:\n",
        "    print(p.name)\n",
        "    display(Image(filename=str(p)))\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}