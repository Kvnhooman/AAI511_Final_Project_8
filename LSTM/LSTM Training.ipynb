{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f28b1286",
   "metadata": {},
   "source": [
    "# Loading Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0bdf55b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import zipfile\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01953112",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 215 raw Beethoven files in ../data/raw_Beethoven\n",
      "  â€¢ train: copied 150 files to ../data/train/beethoven\n",
      "  â€¢ dev: copied 32 files to ../data/dev/beethoven\n",
      "  â€¢ test: copied 33 files to ../data/test/beethoven\n"
     ]
    }
   ],
   "source": [
    "# Split raw Beethoven MIDIs into train/dev/test (70/15/15)\n",
    "# No Beethoven files were in the data set from Module 2\n",
    "# â€”â€”â€” Configuration â€”â€”â€”\n",
    "BASE_DIR = Path('../data')\n",
    "RAW_BEET = BASE_DIR / 'raw_Beethoven'\n",
    "SPLITS   = ['train', 'dev', 'test']\n",
    "LABEL    = 'beethoven'\n",
    "\n",
    "# 1) Gather all .mid files under data/raw_Beethoven\n",
    "all_beet = list(RAW_BEET.rglob('*.mid'))\n",
    "print(f\"Found {len(all_beet)} raw Beethoven files in {RAW_BEET}\")\n",
    "\n",
    "# 2) Split: 70% train, 15% dev, 15% test\n",
    "train_files, temp_files = train_test_split(all_beet, test_size=0.30, random_state=42)\n",
    "dev_files,   test_files = train_test_split(temp_files, test_size=0.50, random_state=42)\n",
    "\n",
    "# 3) Create the target dirs and copy files\n",
    "for split, files in zip(SPLITS, [train_files, dev_files, test_files]):\n",
    "    target_dir = BASE_DIR / split / LABEL\n",
    "    target_dir.mkdir(parents=True, exist_ok=True)\n",
    "    for f in files:\n",
    "        shutil.copy(f, target_dir / f.name)\n",
    "    print(f\"  â€¢ {split}: copied {len(files)} files to {target_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0c7fa678",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: mps\n",
      "Train: (480044, 50, 3), Dev: (41034, 50, 3), Test: (39295, 50, 3)\n",
      "Classes: ['bach' 'beethoven' 'chopin' 'mozart']\n"
     ]
    }
   ],
   "source": [
    "# Paths\n",
    "BASE_DIR   = Path('../data/processed_data')\n",
    "OUTPUT_DIR = BASE_DIR                   \n",
    "\n",
    "# Hyperparameters\n",
    "batch_size    = 32\n",
    "learning_rate = 1e-3\n",
    "num_epochs    = 20\n",
    "\n",
    "# Load data\n",
    "with open(BASE_DIR / 'lstm_train.pkl','rb') as f:\n",
    "    X_train, y_train = pickle.load(f)\n",
    "with open(BASE_DIR / 'lstm_dev.pkl','rb')   as f:\n",
    "    X_dev,   y_dev   = pickle.load(f)\n",
    "with open(BASE_DIR / 'lstm_test.pkl','rb')  as f:\n",
    "    X_test,  y_test  = pickle.load(f)\n",
    "\n",
    "with open(BASE_DIR / 'label_encoder.pkl','rb') as f:\n",
    "    le = pickle.load(f)\n",
    "num_classes = len(le.classes_)\n",
    "input_size  = X_train.shape[2]\n",
    "\n",
    "if   torch.backends.mps.is_available(): device = torch.device('mps')\n",
    "elif torch.cuda.is_available():         device = torch.device('cuda')\n",
    "else:                                   device = torch.device('cpu')\n",
    "\n",
    "print(f\"Device: {device}\")\n",
    "print(f\"Train: {X_train.shape}, Dev: {X_dev.shape}, Test: {X_test.shape}\")\n",
    "print(f\"Classes: {le.classes_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "70f47cb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One training batch X shape: torch.Size([32, 50, 3])\n",
      "One training batch y shape: torch.Size([32])\n"
     ]
    }
   ],
   "source": [
    "# Convert to tensors\n",
    "X_tr = torch.tensor(X_train, dtype=torch.float32).to(device)\n",
    "y_tr = torch.tensor(y_train, dtype=torch.long).to(device)\n",
    "X_dev_t = torch.tensor(X_dev, dtype=torch.float32).to(device)\n",
    "y_dev_t = torch.tensor(y_dev, dtype=torch.long).to(device)\n",
    "\n",
    "# Create TensorDatasets\n",
    "train_ds = TensorDataset(X_tr, y_tr)\n",
    "dev_ds   = TensorDataset(X_dev_t, y_dev_t)\n",
    "\n",
    "# Create DataLoaders\n",
    "train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
    "dev_loader   = DataLoader(dev_ds,   batch_size=batch_size, shuffle=False)\n",
    "#check check\n",
    "batch = next(iter(train_loader))\n",
    "print(\"One training batch X shape:\", batch[0].shape)\n",
    "print(\"One training batch y shape:\", batch[1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b8c8ad58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MusicLSTM(\n",
      "  (lstm): LSTM(3, 128, num_layers=2, batch_first=True, dropout=0.3)\n",
      "  (fc): Linear(in_features=128, out_features=4, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class MusicLSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, num_classes):\n",
    "        super().__init__()\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=input_size,\n",
    "            hidden_size=hidden_size,\n",
    "            num_layers=num_layers,\n",
    "            batch_first=True,\n",
    "            dropout=0.3\n",
    "        )\n",
    "        self.fc = nn.Linear(hidden_size, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (batch, seq_len, input_size)\n",
    "        lstm_out, _ = self.lstm(x)\n",
    "        # Take the output from the last time step\n",
    "        last_output = lstm_out[:, -1, :]     # shape: (batch, hidden_size)\n",
    "        return self.fc(last_output)          # shape: (batch, num_classes)\n",
    "\n",
    "# Hyperparameters for the model\n",
    "hidden_size = 128\n",
    "num_layers  = 2\n",
    "\n",
    "model = MusicLSTM(input_size, hidden_size, num_layers, num_classes).to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2442618b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Criterion: CrossEntropyLoss()\n",
      "Optimizer: Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    capturable: False\n",
      "    decoupled_weight_decay: False\n",
      "    differentiable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    fused: None\n",
      "    lr: 0.001\n",
      "    maximize: False\n",
      "    weight_decay: 0\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Loss function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "best_dev_acc = 0.0\n",
    "\n",
    "print(\"Criterion:\", criterion)\n",
    "print(\"Optimizer:\", optimizer)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d840fd4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  1/20  Train Loss: 0.1066  Dev Loss: 0.0332  Dev Acc: 0.9871\n",
      "  ðŸ”– New best model saved\n",
      "Epoch  2/20  Train Loss: 0.0486  Dev Loss: 0.0535  Dev Acc: 0.9806\n",
      "Epoch  3/20  Train Loss: 0.0327  Dev Loss: 0.0278  Dev Acc: 0.9898\n",
      "  ðŸ”– New best model saved\n",
      "Epoch  4/20  Train Loss: 0.0265  Dev Loss: 0.0498  Dev Acc: 0.9841\n",
      "Epoch  5/20  Train Loss: 0.0232  Dev Loss: 0.0337  Dev Acc: 0.9892\n",
      "Epoch  6/20  Train Loss: 0.0197  Dev Loss: 0.0241  Dev Acc: 0.9914\n",
      "  ðŸ”– New best model saved\n",
      "Epoch  7/20  Train Loss: 0.0186  Dev Loss: 0.1263  Dev Acc: 0.9631\n",
      "Epoch  8/20  Train Loss: 0.0185  Dev Loss: 0.0516  Dev Acc: 0.9885\n",
      "Epoch  9/20  Train Loss: 0.0186  Dev Loss: 0.0547  Dev Acc: 0.9835\n",
      "Epoch 10/20  Train Loss: 0.0171  Dev Loss: 0.0437  Dev Acc: 0.9864\n",
      "Epoch 11/20  Train Loss: 0.0168  Dev Loss: 0.0259  Dev Acc: 0.9920\n",
      "  ðŸ”– New best model saved\n",
      "Epoch 12/20  Train Loss: 0.0155  Dev Loss: 0.0521  Dev Acc: 0.9836\n",
      "Epoch 13/20  Train Loss: 0.0172  Dev Loss: 0.0230  Dev Acc: 0.9920\n",
      "Epoch 14/20  Train Loss: 0.0153  Dev Loss: 0.0459  Dev Acc: 0.9879\n",
      "Epoch 15/20  Train Loss: 0.0141  Dev Loss: 0.0342  Dev Acc: 0.9906\n",
      "Epoch 16/20  Train Loss: 0.0148  Dev Loss: 0.0414  Dev Acc: 0.9889\n",
      "Epoch 17/20  Train Loss: 0.0141  Dev Loss: 0.0353  Dev Acc: 0.9890\n",
      "Epoch 18/20  Train Loss: 0.0132  Dev Loss: 0.0273  Dev Acc: 0.9922\n",
      "  ðŸ”– New best model saved\n",
      "Epoch 19/20  Train Loss: 0.0147  Dev Loss: 0.0448  Dev Acc: 0.9873\n",
      "Epoch 20/20  Train Loss: 0.0140  Dev Loss: 0.0294  Dev Acc: 0.9906\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, num_epochs + 1):\n",
    "    # â€”â€”â€” Trainingâ€”â€”â€”\n",
    "    model.train()\n",
    "    train_losses = []\n",
    "    for Xb, yb in train_loader:\n",
    "        optimizer.zero_grad()            # reset gradients\n",
    "        logits = model(Xb)               # forward pass\n",
    "        loss   = criterion(logits, yb)   # compute loss\n",
    "        loss.backward()                  # backpropagate\n",
    "        optimizer.step()                 # update weights\n",
    "        train_losses.append(loss.item())\n",
    "\n",
    "    avg_train_loss = np.mean(train_losses)\n",
    "\n",
    "    # â€”â€”â€” Validationâ€”â€”â€”\n",
    "    model.eval()\n",
    "    dev_preds, dev_true, dev_losses = [], [], []\n",
    "    with torch.no_grad():\n",
    "        for Xb, yb in dev_loader:\n",
    "            logits = model(Xb)\n",
    "            loss   = criterion(logits, yb)\n",
    "            dev_losses.append(loss.item())\n",
    "            preds = logits.argmax(dim=1).cpu().numpy()\n",
    "            dev_preds.extend(preds)\n",
    "            dev_true.extend(yb.cpu().numpy())\n",
    "\n",
    "    avg_dev_loss = np.mean(dev_losses)\n",
    "    dev_acc      = accuracy_score(dev_true, dev_preds)\n",
    "\n",
    "    #epoch results\n",
    "    print(f\"Epoch {epoch:2d}/{num_epochs}  \"\n",
    "          f\"Train Loss: {avg_train_loss:.4f}  \"\n",
    "          f\"Dev Loss: {avg_dev_loss:.4f}  \"\n",
    "          f\"Dev Acc: {dev_acc:.4f}\")\n",
    "\n",
    "    # Save best model by dev accuracy\n",
    "    if dev_acc > best_dev_acc:\n",
    "        best_dev_acc = dev_acc\n",
    "        torch.save(model.state_dict(), OUTPUT_DIR / 'best_model.pth')\n",
    "        print(\"  ðŸ”– New best model saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "db189fa1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Accuracy: 0.9694\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "        bach       0.98      1.00      0.99     11313\n",
      "   beethoven       0.00      0.00      0.00         0\n",
      "      chopin       0.99      0.88      0.93      9581\n",
      "      mozart       0.95      1.00      0.97     18401\n",
      "\n",
      "    accuracy                           0.97     39295\n",
      "   macro avg       0.73      0.72      0.72     39295\n",
      "weighted avg       0.97      0.97      0.97     39295\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      " [[11312     0     0     1]\n",
      " [    0     0     0     0]\n",
      " [  225     0  8445   911]\n",
      " [    0     0    66 18335]]\n"
     ]
    }
   ],
   "source": [
    "# Load the best model checkpoint\n",
    "best_model = MusicLSTM(input_size, hidden_size, num_layers, num_classes).to(device)\n",
    "best_model.load_state_dict(torch.load(OUTPUT_DIR / 'best_model.pth'))\n",
    "best_model.eval()\n",
    "\n",
    "# Prepare test DataLoader\n",
    "X_te = torch.tensor(X_test, dtype=torch.float32).to(device)\n",
    "y_te = torch.tensor(y_test, dtype=torch.long).to(device)\n",
    "test_loader = DataLoader(TensorDataset(X_te, y_te), batch_size=batch_size)\n",
    "\n",
    "# Collect predictions & true labels\n",
    "test_preds, test_true = [], []\n",
    "with torch.no_grad():\n",
    "    for Xb, yb in test_loader:\n",
    "        logits = best_model(Xb)\n",
    "        preds  = logits.argmax(dim=1).cpu().numpy()\n",
    "        test_preds.extend(preds)\n",
    "        test_true.extend(yb.cpu().numpy())\n",
    "\n",
    "# accuracy\n",
    "test_acc = accuracy_score(test_true, test_preds)\n",
    "print(f\"\\nTest Accuracy: {test_acc:.4f}\\n\")\n",
    "\n",
    "labels = list(range(num_classes))    # [0, 1, 2, 3]\n",
    "names  = le.classes_                 # ['bach', 'beethoven', 'chopin', 'mozart']\n",
    "\n",
    "print(\"Classification Report:\\n\",\n",
    "      classification_report(\n",
    "          test_true,\n",
    "          test_preds,\n",
    "          labels=labels,\n",
    "          target_names=names,\n",
    "          zero_division=0\n",
    "      ))\n",
    "\n",
    "print(\"\\nConfusion Matrix:\\n\",\n",
    "      confusion_matrix(\n",
    "          test_true,\n",
    "          test_preds,\n",
    "          labels=labels\n",
    "      ))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
